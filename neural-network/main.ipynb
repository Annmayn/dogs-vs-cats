{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bite12d0448823a406b82cf7196c7d0953f",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import file_parser\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "import file_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV file \\[file_location, output\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CSV file already exists. Skipping...\n"
    }
   ],
   "source": [
    "dataset_path = \"E:\\MachineLearning\\Datasets\\dogs-vs-cats\\train\"\n",
    "dataset_csv = 'data/data.csv'\n",
    "\n",
    "if not os.path.exists(dataset_csv):\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    df = file_parser.get_all_files()\n",
    "    file_parser.save_as_csv(df,dataset_csv)\n",
    "    print(\"Created csv file\")\n",
    "else:\n",
    "    print(\"CSV file already exists. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train and Test files already exists. Skipping...\n"
    }
   ],
   "source": [
    "x_train_file = 'data/train.h5'\n",
    "x_test_file = 'data/test.h5'\n",
    "image_size_x = 24;\n",
    "image_size_y = 24;\n",
    "train_size = 0.8;\n",
    "if not os.path.exists(x_test_file):\n",
    "    file_parser.split_and_save(dataset_csv, image_size_x, image_size_y, train_size, x_train_file, x_test_file)\n",
    "    print(\"Dataset split and saved as train.h5 and test.h5\")\n",
    "else:\n",
    "    print(\"Train and Test files already exists. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSTOM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def dsigmoid(z):\n",
    "    return z*(1-z)\n",
    "\n",
    "def relu(z):\n",
    "    # max(0,z)\n",
    "    return z*(z>0)\n",
    "\n",
    "# derivative of relu\n",
    "def drelu(z):\n",
    "    return z>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/train.h5','r') as train:\n",
    "    X_train = train.get('X')[()]\n",
    "    y_train = train.get('y')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1728, 20000) (1, 20000)\n"
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/test.h5','r') as test:\n",
    "    X_test = test.get('X')[()]\n",
    "    y_test = test.get('y')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1728, 5000) (1, 5000)\n"
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, y , cache):\n",
    "    W1 = cache['W1']\n",
    "    b1 = cache['b1']\n",
    "    W2 = cache['W2']\n",
    "    b2 = cache['b2']\n",
    "\n",
    "    Z1 = np.dot(W1, X)+b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    return {\n",
    "        \"Z1\":Z1,\n",
    "        \"A1\":A1,\n",
    "        \"Z2\":Z2,\n",
    "        \"A2\":A2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, W, cache):\n",
    "    Z1 = cache['Z1']\n",
    "    A1 = cache['A1']\n",
    "    Z2 = cache['Z2']\n",
    "    A2 = cache['A2']\n",
    "\n",
    "    dZ2 = A2-y\n",
    "    dW2 = np.sum(np.dot(dZ2, A1.T), axis=1, keepdims=True)/m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m\n",
    "\n",
    "    dZ1 = np.dot(W.T, dZ2)*drelu(Z1)\n",
    "    dW1 = np.sum(np.dot(dZ1, X.T), axis=1, keepdims=True)/m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
    "\n",
    "    return {\n",
    "        \"dW2\": dW2,\n",
    "        \"db2\": db2,\n",
    "        \"dW1\": dW1,\n",
    "        \"db1\": db1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(Wcache, cache, learning_rate):\n",
    "    W1 = Wcache[\"W1\"]\n",
    "    W2 = Wcache[\"W2\"]\n",
    "    b1 = Wcache[\"b1\"]\n",
    "    b2 = Wcache[\"b2\"]\n",
    "\n",
    "    dW1 = cache[\"dW1\"]\n",
    "    dW2 = cache[\"dW2\"]\n",
    "    db1 = cache[\"db1\"]\n",
    "    db2 = cache[\"db2\"]\n",
    "\n",
    "\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    \n",
    "    return {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(X, y, Wcache, learning_rate=0.1, stop_criteria=None, num_iterations=5000, print_cost=False):\n",
    "    m = X.shape[0]\n",
    "    _run_time=0\n",
    "    error = stop_criteria+1 or 1\n",
    "    i=0\n",
    "    J = None\n",
    "\n",
    "    while i<num_iterations and abs(error)>stop_criteria:\n",
    "        i+=1\n",
    "        t1=time.time()\n",
    "\n",
    "        cache = forward_propagation(X, y, Wcache)\n",
    "        diffcache = backward_propagation(X, y, Wcache[\"W2\"], cache)\n",
    "        Wcache = update_params(Wcache, diffcache, learning_rate)\n",
    "\n",
    "        a = cache[\"A2\"]>0.5\n",
    "        J_prev = J or 0\n",
    "        J = np.sum(y!=a)/m\n",
    "        # J = -np.sum(y*np.log(a)+(1-y)*np.log(1-a))/m\n",
    "        error = abs(J-J_prev)\n",
    "        \n",
    "        t2=time.time()\n",
    "        _run_time+=(t2-t1)\n",
    "        if print_cost:\n",
    "            print(\"Iteration {i}: cost = {cost}, execution time: {time:.3f}s, error: {err:.5f}\".format(i=i, cost=J, time=t2-t1, err=error))\n",
    "    \n",
    "    \n",
    "    print(\"\\nAfter {n} iterations: cost = {cost}, total execution time: {time:.3f}s\".format(n=i, cost=J, time=_run_time))\n",
    "    print(X.shape)\n",
    "    print(len(a[0]))\n",
    "    print(np.sum(y==a)/X.shape[1]*100)\n",
    "    return {\n",
    "        \"w\": Wcache['W2'].tolist(),\n",
    "        \"b\": Wcache['b2'],\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"cost\": J\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing NN with 1 hidden layer with 4 nodes and output layer with 1 node.\n",
    "\n",
    "Dimensions of parameters:\n",
    "X = (nx, m)  # m-> no. of examples, nx->size of array representing 1 image\n",
    "\n",
    "W1 = dW1 = (4, nx) \n",
    "\n",
    "b1 = db1 = (4,1)\n",
    "\n",
    "Z1 = A1 = dZ1 = dA1 = (4,m)\n",
    "\n",
    "W2 = dW2 = (1,4)\n",
    "\n",
    "b2 = db2 = (1,1)\n",
    "\n",
    "Z2 = A2 = dZ2 = dA2 = (1,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration 1: cost = 5.782986111111111, execution time: 0.092s, error: 5.78299\nIteration 2: cost = 5.776041666666667, execution time: 0.066s, error: 0.00694\nIteration 3: cost = 5.776041666666667, execution time: 0.071s, error: 0.00000\n\nAfter 3 iterations: cost = 5.776041666666667, total execution time: 0.228s\n(1728, 20000)\n20000\n50.095\n"
    }
   ],
   "source": [
    "m=X_train.shape[0]\n",
    "learning_rate = 0.01\n",
    "W1 = np.random.randn(4,m)*0.001\n",
    "b1 = np.zeros((4,1))\n",
    "W2 = np.random.randn(1,4)*0.001\n",
    "b2 = np.zeros((1,1))\n",
    "wcache = {\n",
    "    \"W1\":W1,\n",
    "    \"b1\":b1,\n",
    "    \"W2\":W2,\n",
    "    \"b2\":b2\n",
    "}\n",
    "n=100\n",
    "show_epoch_details=True\n",
    "stop_criteria=0.0001\n",
    "\n",
    "res = run_nn(X_train, y_train, wcache, learning_rate, stop_criteria=stop_criteria, num_iterations=n,print_cost=show_epoch_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(y-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 1],\n       [-2],\n       [ 3]])"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "a = np.array([[1,-2,3]])\n",
    "a.resize(3,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3]])\n",
    "b = np.array([[2,2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[False,  True, False]])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}